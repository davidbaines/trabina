{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5377f3f-bc7a-4d70-bccb-02052c178d0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Match Biblical names from multiple versions and across languages.\n",
    "The JHU trabina project has done this with a list of 1128 names across 531 languages.\n",
    "\n",
    "It would be good also to 'read' through the projects or extracts we have to do a similar matching.\n",
    "\n",
    "We have some hand crafted data to get started: The Macula dataset and also the All Biblical Terms and Major Biblical Terms lists from Paratext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d237af99-90bc-4be6-819c-b58b93d54a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import csv\n",
    "from collections import Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a02679e-a4a2-42e2-85bd-af4ed91e9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_macula_df(file, sep=\"\\t\"):\n",
    "\n",
    "    # Load the macula data. Note that the data has already been filtered for names-only using XBase.\n",
    "    macula_df = pd.read_csv(file, dtype=str, sep=sep)\n",
    "    macula_df.fillna('', inplace=True)\n",
    "    \n",
    "    #print(macula_df)\n",
    "    \n",
    "    #Index(['ref', 'Original unicode', 'Hebrew Original', 'Aramaic Original', 'Greek Original', 'Greek lemma', 'Greek normalized', 'Greek gloss', 'English gloss', 'Mandarin gloss']\n",
    "    \n",
    "    return macula_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5767e3ef-3e6c-4094-b6d3-adac5f8b97ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The simple macula dataframe has these columns:\n",
      "Index(['Original unicode', 'Greek lemma', 'Greek normalized', 'Greek gloss',\n",
      "       'English gloss', 'Mandarin gloss'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original unicode</th>\n",
       "      <th>Greek lemma</th>\n",
       "      <th>Greek normalized</th>\n",
       "      <th>Greek gloss</th>\n",
       "      <th>English gloss</th>\n",
       "      <th>Mandarin gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>יְהוָ֥ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>יְהוָ֤ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>יְהוָ֨ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>יְהוָ֧ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>κύριος</td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>עֵ֖דֶן</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>εδεμ</td>\n",
       "      <td>Eden</td>\n",
       "      <td>伊甸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38793</th>\n",
       "      <td>ΒΑΒΥΛΩΝ</td>\n",
       "      <td>Βαβυλών</td>\n",
       "      <td>ΒΑΒΥΛΩΝ</td>\n",
       "      <td></td>\n",
       "      <td>Babylon</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38801</th>\n",
       "      <td>Ἰησοῦ</td>\n",
       "      <td>Ἰησοῦς</td>\n",
       "      <td>Ἰησοῦ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38802</th>\n",
       "      <td>Χριστοῦ</td>\n",
       "      <td>Χριστός</td>\n",
       "      <td>Χριστοῦ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38805</th>\n",
       "      <td>Γὼγ</td>\n",
       "      <td>Γώγ</td>\n",
       "      <td>Γώγ</td>\n",
       "      <td></td>\n",
       "      <td>Gog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38806</th>\n",
       "      <td>Μαγώγ,</td>\n",
       "      <td>Μαγώγ</td>\n",
       "      <td>Μαγώγ</td>\n",
       "      <td></td>\n",
       "      <td>Magog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15448 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Original unicode Greek lemma Greek normalized Greek gloss English gloss  \\\n",
       "0              יְהוָ֥ה                                                   LORD   \n",
       "1              יְהוָ֤ה                                                   LORD   \n",
       "2              יְהוָ֨ה                                                   LORD   \n",
       "3              יְהוָ֧ה                                   κύριος          LORD   \n",
       "4               עֵ֖דֶן                                     εδεμ          Eden   \n",
       "...                ...         ...              ...         ...           ...   \n",
       "38793          ΒΑΒΥΛΩΝ     Βαβυλών          ΒΑΒΥΛΩΝ                   Babylon   \n",
       "38801            Ἰησοῦ      Ἰησοῦς            Ἰησοῦ                             \n",
       "38802          Χριστοῦ     Χριστός          Χριστοῦ                             \n",
       "38805              Γὼγ         Γώγ              Γώγ                       Gog   \n",
       "38806           Μαγώγ,       Μαγώγ            Μαγώγ                     Magog   \n",
       "\n",
       "      Mandarin gloss  \n",
       "0                耶和华  \n",
       "1                耶和华  \n",
       "2                耶和华  \n",
       "3                耶和华  \n",
       "4                 伊甸  \n",
       "...              ...  \n",
       "38793                 \n",
       "38801                 \n",
       "38802                 \n",
       "38805                 \n",
       "38806                 \n",
       "\n",
       "[15448 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = Path(\"D:/GitHub/trabina/data\") \n",
    "by_lang_folder = data_folder / \"by-lang\"\n",
    "jhu_filename = \"eng\"\n",
    "compare_col = \"English gloss\"\n",
    "english_names_file = by_lang_folder / jhu_filename\n",
    "updated_macula_data_tsv = data_folder / \"updated_macula_names.tsv\"\n",
    "\n",
    "macula_data_tsv = data_folder / \"macula_names.tsv\"\n",
    "macula_df = get_macula_df(macula_data_tsv)\n",
    "\n",
    "simple_df = macula_df.drop(columns= ['ref','Hebrew Original', 'Aramaic Original', 'Greek Original'])\n",
    "#Remove duplicate rows from the simple_df\n",
    "simple_df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "print(f\"\\nThe simple macula dataframe has these columns:\\n{simple_df.columns}\")\n",
    "simple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570bdc7e-7371-4613-bb01-42a3d0552a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The simple macula dataframe has these columns:\n",
      "Index(['Original unicode', 'Greek lemma', 'Greek normalized', 'Greek gloss',\n",
      "       'English gloss', 'Mandarin gloss'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original unicode</th>\n",
       "      <th>Greek lemma</th>\n",
       "      <th>Greek normalized</th>\n",
       "      <th>Greek gloss</th>\n",
       "      <th>English gloss</th>\n",
       "      <th>Mandarin gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>יְהוָ֥ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>יְהוָ֤ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>יְהוָ֨ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>יְהוָ֧ה</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>κύριος</td>\n",
       "      <td>LORD</td>\n",
       "      <td>耶和华</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>עֵ֖דֶן</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>εδεμ</td>\n",
       "      <td>Eden</td>\n",
       "      <td>伊甸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38793</th>\n",
       "      <td>ΒΑΒΥΛΩΝ</td>\n",
       "      <td>Βαβυλών</td>\n",
       "      <td>ΒΑΒΥΛΩΝ</td>\n",
       "      <td></td>\n",
       "      <td>Babylon</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38801</th>\n",
       "      <td>Ἰησοῦ</td>\n",
       "      <td>Ἰησοῦς</td>\n",
       "      <td>Ἰησοῦ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38802</th>\n",
       "      <td>Χριστοῦ</td>\n",
       "      <td>Χριστός</td>\n",
       "      <td>Χριστοῦ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38805</th>\n",
       "      <td>Γὼγ</td>\n",
       "      <td>Γώγ</td>\n",
       "      <td>Γώγ</td>\n",
       "      <td></td>\n",
       "      <td>Gog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38806</th>\n",
       "      <td>Μαγώγ,</td>\n",
       "      <td>Μαγώγ</td>\n",
       "      <td>Μαγώγ</td>\n",
       "      <td></td>\n",
       "      <td>Magog</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15448 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Original unicode Greek lemma Greek normalized Greek gloss English gloss  \\\n",
       "0              יְהוָ֥ה                                                   LORD   \n",
       "1              יְהוָ֤ה                                                   LORD   \n",
       "2              יְהוָ֨ה                                                   LORD   \n",
       "3              יְהוָ֧ה                                   κύριος          LORD   \n",
       "4               עֵ֖דֶן                                     εδεμ          Eden   \n",
       "...                ...         ...              ...         ...           ...   \n",
       "38793          ΒΑΒΥΛΩΝ     Βαβυλών          ΒΑΒΥΛΩΝ                   Babylon   \n",
       "38801            Ἰησοῦ      Ἰησοῦς            Ἰησοῦ                             \n",
       "38802          Χριστοῦ     Χριστός          Χριστοῦ                             \n",
       "38805              Γὼγ         Γώγ              Γώγ                       Gog   \n",
       "38806           Μαγώγ,       Μαγώγ            Μαγώγ                     Magog   \n",
       "\n",
       "      Mandarin gloss  \n",
       "0                耶和华  \n",
       "1                耶和华  \n",
       "2                耶和华  \n",
       "3                耶和华  \n",
       "4                 伊甸  \n",
       "...              ...  \n",
       "38793                 \n",
       "38801                 \n",
       "38802                 \n",
       "38805                 \n",
       "38806                 \n",
       "\n",
       "[15448 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_folder = Path(\"D:/GitHub/trabina/data\") \n",
    "by_lang_folder = data_folder / \"by-lang\"\n",
    "jhu_filename = \"eng\"\n",
    "compare_col = \"English gloss\"\n",
    "english_names_file = by_lang_folder / jhu_filename\n",
    "updated_macula_data_tsv = data_folder / \"updated_macula_names.tsv\"\n",
    "\n",
    "macula_data_tsv = data_folder / \"macula_names.tsv\"\n",
    "macula_df = get_macula_df(macula_data_tsv)\n",
    "\n",
    "simple_df = macula_df.drop(columns= ['ref','Hebrew Original', 'Aramaic Original', 'Greek Original'])\n",
    "#Remove duplicate rows from the simple_df\n",
    "simple_df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "print(f\"\\nThe simple macula dataframe has these columns:\\n{simple_df.columns}\")\n",
    "simple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33316b1c-ba52-401c-9b26-08e9b16afa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_matrix(folder):\n",
    "    \n",
    "    all_names = dict()\n",
    "    \n",
    "    folder = Path(folder)\n",
    "    files = sorted(folder.glob(r'*'))\n",
    "    #print([file.name[0:3] for file in files])\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as fin:\n",
    "            names = [name.strip('\\n').title() for name in fin.readlines()]\n",
    "            all_names[file.name] = names   \n",
    "    \n",
    "    return all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41181a1f-8380-481c-a8b9-f9ce71ab2414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The JHU dataframe has these columns:\n",
      " Index(['aai_aai', 'aak_aak', 'aau_aau', 'abt_maprik', 'aby_aby', 'acd_acd',\n",
      "       'ace_ace', 'acf_acf', 'acn_acn', 'acr_cubulcu',\n",
      "       ...\n",
      "       'tpa_tpa', 'tpi_tpi', 'tpm_tpm', 'tsn_1908', 'tur_2009', 'ukr_1871',\n",
      "       'urd_arabic', 'vie_1926compounds', 'xho_1996', 'zul_zul'],\n",
      "      dtype='object', length=592)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aai_aai</th>\n",
       "      <th>aak_aak</th>\n",
       "      <th>aau_aau</th>\n",
       "      <th>abt_maprik</th>\n",
       "      <th>aby_aby</th>\n",
       "      <th>acd_acd</th>\n",
       "      <th>ace_ace</th>\n",
       "      <th>acf_acf</th>\n",
       "      <th>acn_acn</th>\n",
       "      <th>acr_cubulcu</th>\n",
       "      <th>...</th>\n",
       "      <th>tpa_tpa</th>\n",
       "      <th>tpi_tpi</th>\n",
       "      <th>tpm_tpm</th>\n",
       "      <th>tsn_1908</th>\n",
       "      <th>tur_2009</th>\n",
       "      <th>ukr_1871</th>\n",
       "      <th>urd_arabic</th>\n",
       "      <th>vie_1926compounds</th>\n",
       "      <th>xho_1996</th>\n",
       "      <th>zul_zul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>Erono</td>\n",
       "      <td>Aron</td>\n",
       "      <td>Eron</td>\n",
       "      <td>Eroni</td>\n",
       "      <td>Aron</td>\n",
       "      <td>Harun</td>\n",
       "      <td>Éronn</td>\n",
       "      <td>Aron</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Aron</td>\n",
       "      <td>Aarɔn</td>\n",
       "      <td>Arone</td>\n",
       "      <td>Harun</td>\n",
       "      <td>Аарон</td>\n",
       "      <td>ہارون</td>\n",
       "      <td>A-Rôn</td>\n",
       "      <td>Uaron</td>\n",
       "      <td>Ku-Aroni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abaddon</td>\n",
       "      <td>Abadonoyɨ</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Abadoni</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Abadonn</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Abadɔn</td>\n",
       "      <td>Abatone</td>\n",
       "      <td>Abadon</td>\n",
       "      <td>Авадон</td>\n",
       "      <td>ابدون</td>\n",
       "      <td>A-Ba-Đôn</td>\n",
       "      <td>Uapoliyon</td>\n",
       "      <td>Lingu-Abadoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Abarim</td>\n",
       "      <td>Abarim</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>A-Ba-Rim</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abba</td>\n",
       "      <td>Ápe</td>\n",
       "      <td>Abba</td>\n",
       "      <td>Wao</td>\n",
       "      <td>Ufane</td>\n",
       "      <td>Sɛi</td>\n",
       "      <td>Oe</td>\n",
       "      <td>Papa</td>\n",
       "      <td>Aba</td>\n",
       "      <td>Chawesaj</td>\n",
       "      <td>...</td>\n",
       "      <td>Ama'U</td>\n",
       "      <td>Aba</td>\n",
       "      <td>Kote</td>\n",
       "      <td>Aba</td>\n",
       "      <td>Abba</td>\n",
       "      <td>Авва</td>\n",
       "      <td>ابّا</td>\n",
       "      <td>A-Ba</td>\n",
       "      <td>Tata</td>\n",
       "      <td>Aba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Apdon</td>\n",
       "      <td>Abdɔn</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Áp-Đôn</td>\n",
       "      <td>Uabdon</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Soba</td>\n",
       "      <td>Zoba</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Xô-Ba</td>\n",
       "      <td>Wasezobha</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Sora</td>\n",
       "      <td>Zora</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Xô-Ra</td>\n",
       "      <td>Ezora</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Zerubbabel</td>\n",
       "      <td>Serababero</td>\n",
       "      <td>Serubabel</td>\n",
       "      <td>Serababel</td>\n",
       "      <td>Serubabeo</td>\n",
       "      <td>Serubabelɛ</td>\n",
       "      <td>Zerubabel</td>\n",
       "      <td>Zèròbabèl</td>\n",
       "      <td>Zerubabe</td>\n",
       "      <td>Zorobabel</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Serubabel</td>\n",
       "      <td>Zɛrubabɛl</td>\n",
       "      <td>Serubabele</td>\n",
       "      <td>Zerubabel</td>\n",
       "      <td>Заровавель</td>\n",
       "      <td>زرُبابل</td>\n",
       "      <td>Xô-Rô-Ba-Bên</td>\n",
       "      <td>Uzerubhabheli</td>\n",
       "      <td>Uzorobabeli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Suf</td>\n",
       "      <td>Zuf</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Xu-Phơ</td>\n",
       "      <td>Kazufi</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>Sur</td>\n",
       "      <td>Zur</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Xu-Rơ</td>\n",
       "      <td>Uzure</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aai_aai     aak_aak    aau_aau abt_maprik    aby_aby     acd_acd  \\\n",
       "0          Aaron       Erono       Aron       Eron      Eroni        Aron   \n",
       "1        Abaddon   Abadonoyɨ     Abadon     Abadon    Abadoni      Abadon   \n",
       "2              -           -          -          -          -           -   \n",
       "3           Abba         Ápe       Abba        Wao      Ufane         Sɛi   \n",
       "4              -           -          -          -          -           -   \n",
       "...          ...         ...        ...        ...        ...         ...   \n",
       "1124           -           -          -          -          -           -   \n",
       "1125           -           -          -          -          -           -   \n",
       "1126  Zerubbabel  Serababero  Serubabel  Serababel  Serubabeo  Serubabelɛ   \n",
       "1127           -           -          -          -          -           -   \n",
       "1128           -           -          -          -          -           -   \n",
       "\n",
       "        ace_ace    acf_acf   acn_acn acr_cubulcu  ... tpa_tpa    tpi_tpi  \\\n",
       "0         Harun      Éronn      Aron       Aaron  ...       -       Aron   \n",
       "1        Abadon    Abadonn    Abadon      Abadon  ...       -     Abadon   \n",
       "2             -          -         -           -  ...       -     Abarim   \n",
       "3            Oe       Papa       Aba    Chawesaj  ...   Ama'U        Aba   \n",
       "4             -          -         -           -  ...       -      Apdon   \n",
       "...         ...        ...       ...         ...  ...     ...        ...   \n",
       "1124          -          -         -           -  ...       -       Soba   \n",
       "1125          -          -         -           -  ...       -       Sora   \n",
       "1126  Zerubabel  Zèròbabèl  Zerubabe   Zorobabel  ...       -  Serubabel   \n",
       "1127          -          -         -           -  ...       -        Suf   \n",
       "1128          -          -         -           -  ...       -        Sur   \n",
       "\n",
       "        tpm_tpm    tsn_1908   tur_2009    ukr_1871 urd_arabic  \\\n",
       "0         Aarɔn       Arone      Harun       Аарон      ہارون   \n",
       "1        Abadɔn     Abatone     Abadon      Авадон      ابدون   \n",
       "2        Abarim           -          -           -          -   \n",
       "3          Kote         Aba       Abba        Авва       ابّا   \n",
       "4         Abdɔn           -          -           -          -   \n",
       "...         ...         ...        ...         ...        ...   \n",
       "1124       Zoba           -          -           -          -   \n",
       "1125       Zora           -          -           -          -   \n",
       "1126  Zɛrubabɛl  Serubabele  Zerubabel  Заровавель    زرُبابل   \n",
       "1127        Zuf           -          -           -          -   \n",
       "1128        Zur           -          -           -          -   \n",
       "\n",
       "     vie_1926compounds       xho_1996        zul_zul  \n",
       "0                A-Rôn          Uaron       Ku-Aroni  \n",
       "1             A-Ba-Đôn      Uapoliyon  Lingu-Abadoni  \n",
       "2             A-Ba-Rim                             -  \n",
       "3                 A-Ba           Tata            Aba  \n",
       "4               Áp-Đôn         Uabdon              -  \n",
       "...                ...            ...            ...  \n",
       "1124             Xô-Ba      Wasezobha              -  \n",
       "1125             Xô-Ra          Ezora              -  \n",
       "1126      Xô-Rô-Ba-Bên  Uzerubhabheli    Uzorobabeli  \n",
       "1127            Xu-Phơ         Kazufi              -  \n",
       "1128             Xu-Rơ          Uzure              -  \n",
       "\n",
       "[1129 rows x 592 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all the names and make a dataframe\n",
    "all_jhu_names = get_name_matrix(by_lang_folder)\n",
    "jhu_df = pd.DataFrame.from_dict(all_jhu_names, dtype=str)\n",
    "\n",
    "print(f\"\\nThe JHU dataframe has these columns:\\n {jhu_df.columns}\")  \n",
    "jhu_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99e1529-3352-4262-90c2-68aa41e01290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aai_aai</th>\n",
       "      <th>aak_aak</th>\n",
       "      <th>aau_aau</th>\n",
       "      <th>abt_maprik</th>\n",
       "      <th>aby_aby</th>\n",
       "      <th>acd_acd</th>\n",
       "      <th>ace_ace</th>\n",
       "      <th>acf_acf</th>\n",
       "      <th>acn_acn</th>\n",
       "      <th>acr_cubulcu</th>\n",
       "      <th>...</th>\n",
       "      <th>tpa_tpa</th>\n",
       "      <th>tpi_tpi</th>\n",
       "      <th>tpm_tpm</th>\n",
       "      <th>tsn_1908</th>\n",
       "      <th>tur_2009</th>\n",
       "      <th>ukr_1871</th>\n",
       "      <th>urd_arabic</th>\n",
       "      <th>vie_1926compounds</th>\n",
       "      <th>xho_1996</th>\n",
       "      <th>zul_zul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>...</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>483</td>\n",
       "      <td>472</td>\n",
       "      <td>481</td>\n",
       "      <td>465</td>\n",
       "      <td>456</td>\n",
       "      <td>478</td>\n",
       "      <td>470</td>\n",
       "      <td>491</td>\n",
       "      <td>471</td>\n",
       "      <td>482</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>974</td>\n",
       "      <td>953</td>\n",
       "      <td>488</td>\n",
       "      <td>425</td>\n",
       "      <td>492</td>\n",
       "      <td>480</td>\n",
       "      <td>988</td>\n",
       "      <td>1006</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>556</td>\n",
       "      <td>573</td>\n",
       "      <td>549</td>\n",
       "      <td>576</td>\n",
       "      <td>583</td>\n",
       "      <td>558</td>\n",
       "      <td>568</td>\n",
       "      <td>553</td>\n",
       "      <td>551</td>\n",
       "      <td>555</td>\n",
       "      <td>...</td>\n",
       "      <td>1006</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>548</td>\n",
       "      <td>619</td>\n",
       "      <td>551</td>\n",
       "      <td>554</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aai_aai aak_aak aau_aau abt_maprik aby_aby acd_acd ace_ace acf_acf  \\\n",
       "count     1129    1129    1129       1129    1129    1129    1129    1129   \n",
       "unique     483     472     481        465     456     478     470     491   \n",
       "top          -       -       -          -       -       -       -       -   \n",
       "freq       556     573     549        576     583     558     568     553   \n",
       "\n",
       "       acn_acn acr_cubulcu  ... tpa_tpa tpi_tpi tpm_tpm tsn_1908 tur_2009  \\\n",
       "count     1129        1129  ...    1129    1129    1129     1129     1129   \n",
       "unique     471         482  ...      96     974     953      488      425   \n",
       "top          -           -  ...       -       -       -        -        -   \n",
       "freq       551         555  ...    1006      33      70      548      619   \n",
       "\n",
       "       ukr_1871 urd_arabic vie_1926compounds xho_1996 zul_zul  \n",
       "count      1129       1129              1129     1129    1129  \n",
       "unique      492        480               988     1006     493  \n",
       "top           -          -                 -        -       -  \n",
       "freq        551        554                26       50     568  \n",
       "\n",
       "[4 rows x 592 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jhu_df = jhu_df.set_index([\"eng\"], drop=True, append=False, inplace=False, verify_integrity=False)\n",
    "jhu_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c5fd0-c9bc-4f1c-b742-36e1be5f49a6",
   "metadata": {},
   "source": [
    "Not sure that merging like this is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ec0ab6-05b3-4647-b2d1-db93308f3c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Concatenate the two dataframes joining on exact matches of \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 'English gloss' and jhu_eng columns. Retain both.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjhu_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimple_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnglish gloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_merge\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatched_on_eng\u001b[39m\u001b[38;5;124m\"\u001b[39m},inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m merged_df\n",
      "File \u001b[1;32mC:\\Python38\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mC:\\Python38\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:704\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python38\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1261\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1257\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1258\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1259\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1260\u001b[0m     ):\n\u001b[1;32m-> 1261\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "#Concatenate the two dataframes joining on exact matches of \n",
    "# 'English gloss' and jhu_eng columns. Retain both.\n",
    "\n",
    "merged_df = pd.merge(jhu_df, simple_df, how='inner', left_index=True,right_on='English gloss', indicator=True)\n",
    "merged_df.rename(columns={\"_merge\": \"matched_on_eng\"},inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557fbc17-a9ca-4b8f-8a8c-e743862569ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_df.index\n",
    "#jhu_df['eng']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6d6ae-f23c-47db-b820-38cbeca5cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the All terms data from silnlp\n",
    "sil_assets_path = Path('D:/GitHub/silnlp/silnlp/assets')\n",
    "all_terms_file = sil_assets_path / 'All-metadata.txt'\n",
    "\n",
    "all_terms = pd.read_table(all_terms_file,header=None, usecols=[0]).squeeze(\"columns\")\n",
    "all_terms.rename('terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ce35d-1341-44cf-b137-3fc59d8df3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into words\n",
    "terms_df = all_terms.str.split(' ', expand=True)\n",
    "terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0976582-7adb-4b18-b459-23e07045fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_df.rename({0: \"term\", 1: \"note\"}, axis=\"columns\", inplace=True)\n",
    "terms_df['AR'] = terms_df['note'] == '(AR)'\n",
    "terms_df['DC'] = terms_df['note'] == '(DC)'\n",
    "terms_df.drop(columns=['note'],inplace=True)\n",
    "terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5a018-6a1d-4f27-b0c5-51a0a93dffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Major terms data from silnlp\n",
    "sil_assets_path = Path('D:/GitHub/silnlp/silnlp/assets')\n",
    "major_terms_file = sil_assets_path / 'Major-metadata.txt'\n",
    "\n",
    "major_terms = pd.read_table(major_terms_file,header=None)\n",
    "major_terms.rename({0: \"term\", 1: \"domain\", 2:'category'}, axis=\"columns\", inplace=True)\n",
    "major_terms[['term', 'note']] = major_terms['term'].str.split(' ', 1, expand=True)\n",
    "\n",
    "major_terms[['term', 'sense']] = major_terms['term'].str.split('-', 1, expand=True)\n",
    "major_terms['AR'] = major_terms['note'] == '(AR)'\n",
    "major_terms['DC'] = major_terms['note'] == '(DC)'\n",
    "major_terms.drop(columns=['note'],inplace=True)\n",
    "\n",
    "major_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8f8cb-63b1-49cd-9180-e335c5e326b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "major_terms.to_csv(r\"D:\\GitHub\\davidbaines\\trabina\\data\\major_terms.txt\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e73180e-3a38-4999-be9d-0a0e00856a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many of the 8648 major terms are in the All terms data?\n",
    "major_terms['all_terms_exact']=major_terms['term'].map(terms_df['term'].value_counts())\n",
    "major_terms['all_terms_exact'] = major_terms['all_terms_exact'].fillna(0)\n",
    "major_terms.sort_values('all_terms_exact',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a05eb0-a430-4970-a026-1a8f614678c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These major terms aren't found exactly in the All-metadata.\n",
    "# major_terms.loc[major_terms['all_terms_exact'].isna()]\n",
    "major_terms.loc[major_terms['all_terms_exact'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263b788-260b-4d3c-b7fd-6b31de3b55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = major_terms['all_terms_exact'] \n",
    "count = col[col != 0].count()\n",
    "print(f\"There are {count} major-metadata terms that appear exactly in the All metadata file.\")\n",
    "print(f\"There are {len(major_terms) - count} major-metadata terms that don't appear exactly in the All metadata file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854b830-42b1-4dc5-9a49-e5760441ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(reference_col, source_col):\n",
    "    matches = source_col.map(reference_col.value_counts()).fillna(0).astype(int)\n",
    "    # Return count of values greater than 0 \n",
    "    return matches[matches > 0].count()\n",
    "\n",
    "#This is very slow.\n",
    "#def find_matches(reference_col, source_col):\n",
    "#    matches = [source for source in source_col if source in reference_col.unique()]\n",
    "#    return matches\n",
    "\n",
    "# This is also slow.\n",
    "def find_matches(reference_col, source_col):\n",
    "    matches = source_col.map(reference_col.value_counts()).fillna(0).astype(int)\n",
    "    # Return values greater than 0 \n",
    "    return matches[matches > 0]\n",
    "\n",
    "# This is almost instant.\n",
    "def find_matches(reference_col, source_col):\n",
    "    return set(source_col).intersection(set(reference_col))\n",
    "\n",
    "def report_matches(ref_df, ref_columns, search_dict):\n",
    "    \n",
    "    for name, col in search_dict.items():\n",
    "        all_matches = set()\n",
    "        match_count = 0\n",
    "        unique_values = col.unique()\n",
    "        print(f\"Searching for the {len(unique_values)} '{name}' in the .\")\n",
    "        for ref_column in ref_columns:\n",
    "            matches = find_matches(ref_df[ref_column],unique_values)\n",
    "            match_count += len(matches)\n",
    "            print(f\"There are {len(matches)} found in the Macula '{ref_column}' column.\")\n",
    "            all_matches = all_matches.union(matches)\n",
    "\n",
    "        print(f\"{match_count} '{name}' matched of which {len(all_matches)} are unique.\")\n",
    "        print(sorted(all_matches))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe8cbc-0061-4fc2-abd3-f691d3eb1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many terms from All, Major and JHU (eng) occur in the Macula data.\n",
    "# Macula Index(['Original unicode', 'Greek lemma', 'Greek normalized', 'Greek gloss', 'English gloss', 'Mandarin gloss']\n",
    "\n",
    "terms_macula         = simple_df['Original unicode']\n",
    "terms_macula_english = simple_df['English gloss']\n",
    "\n",
    "terms_all     = terms_df['term']\n",
    "terms_major   = major_terms['term']\n",
    "terms_jhu_eng = jhu_df['eng']\n",
    "\n",
    "#print(f\"There are {count_matches(terms_macula,terms_all)}   all_terms out of {len(terms_all)} found in the Macula 'Original unicode' column.\")\n",
    "#print(f\"There are {count_matches(terms_macula,terms_major)} major_terms out of {len(terms_major)} found in the Macula 'Original unicode' column.\")\n",
    "#print(f\"There are {count_matches(terms_macula_english,terms_jhu_eng)} jhu_eng terms out of {len(terms_jhu_eng)} found in the Macula 'Original unicode' column.\")\n",
    "\n",
    "# How many of these Original language terms are found exactly as a key in other lists?\n",
    "macula_search_columns = ['Original unicode', 'Hebrew Original', 'Aramaic Original', 'Greek Original', 'Greek lemma', 'Greek normalized', 'Greek gloss']\n",
    "search = {'All terms':terms_all, 'Major terms':terms_major}\n",
    "report_matches(macula_df, macula_search_columns, search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887fc74-fc12-4c4f-9fc7-67e0c38457f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "macula_search_columns = ['English gloss']\n",
    "search = {'JHU eng terms':terms_jhu_eng}\n",
    "report_matches(macula_df, macula_search_columns, search)\n",
    "\n",
    "macula_search_columns = ['Original unicode', 'Greek Original', 'Greek lemma', 'Greek normalized', 'Greek gloss']\n",
    "search = {'JHU grc_accented_terms' : jhu_df['grc_accented'], 'JHU ell_helenic1 terms' : jhu_df['ell_hellenic1']}\n",
    "report_matches(macula_df, macula_search_columns, search)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45e914-c571-41ac-9f53-8d537d938379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324b7cc-4809-4be5-b112-ca5c33ae8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(wrong_options,correct_options):\n",
    "    names_array=[]\n",
    "    ratio_array=[]    \n",
    "    for wrong_option in wrong_options:\n",
    "        if wrong_option in correct_options:\n",
    "            names_array.append(wrong_option)\n",
    "            ratio_array.append('100')\n",
    "        else:   \n",
    "            x=process.extractOne(wrong_option,correct_options,scorer=fuzz.token_set_ratio)\n",
    "            names_array.append(x[0])\n",
    "            ratio_array.append(x[1])\n",
    "    return names_array,ratio_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3359fd7-4f70-40b1-989e-c4ecaf802574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(reference_col, source_col):\n",
    "    str2Match = source_col.fillna('').tolist()\n",
    "    strOptions = reference_col.fillna('').tolist()\n",
    "    \n",
    "    matches = source_col.map(reference_col.value_counts()).fillna(0).astype(int)\n",
    "    # Return count of values greater than 0 \n",
    "    return matches[matches > 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e89468-2665-4fc4-984e-e5c0ff9e7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_matches = terms_major.map(terms_macula.value_counts()).fillna(0).astype(int)\n",
    "# Return count of values greater than 0 \n",
    "print(major_matches[major_matches > 0].count())\n",
    "print(major_matches)\n",
    "\n",
    "#all_name_match,   all_ratio_match = checker(terms_macula,terms_all[0:100])\n",
    "#major_name_match, major_ratio_match=checker(terms_macula,terms_major)\n",
    "\n",
    "#terms_df['fuzzy_match']=pd.Series(all_name_match)\n",
    "#terms_df['fuzzy_ratio']=pd.Series(all_ratio_match)\n",
    "#print(all_name_match,all_ratio_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be476712-ef3d-4486-bd44-8fdc1db53ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(all_name_match),len(all_ratio_match))\n",
    "#all_fuzzy_matches = pd.DataFrame.from_dict({'Original unicode': terms_macula, 'all_metadata fuzzy match' : all_name_match, 'all_metadata fuzzy ratio' :all_ratio_match})\n",
    "#all_fuzzy_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f55c7-51b6-4597-ae69-ab9a52deb608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_terms_from_files(folder,filenames):\n",
    "    \n",
    "    all_names = dict()\n",
    "    \n",
    "    folder = Path(folder)\n",
    "    files = [folder / filename for filename in filenames]\n",
    "    #print([file.name[0:3] for file in files])\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as fin:\n",
    "            names = [name.strip('\\n').title() for name in fin.readlines()]\n",
    "            all_names[file.name] = names   \n",
    "    \n",
    "    return all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20179af5-ba01-4641-8129-dd1cc6495355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the Major terms metadata from silnlp\n",
    "sil_assets_path = Path('D:/GitHub/silnlp/silnlp/assets')\n",
    "source_major_terms_file = sil_assets_path / 'Major-metadata.txt'\n",
    "\n",
    "source_major_terms = pd.read_table(source_major_terms_file,header=None)\n",
    "source_major_terms.rename({0: \"term\", 1: \"domain\", 2:'category'}, axis=\"columns\", inplace=True)\n",
    "source_major_terms[['term', 'note']] = source_major_terms['term'].str.split(' ', 1, expand=True)\n",
    "\n",
    "source_major_terms[['term', 'sense']] = source_major_terms['term'].str.split('-', 1, expand=True)\n",
    "source_major_terms['AR'] = source_major_terms['note'] == '(AR)'\n",
    "source_major_terms['DC'] = source_major_terms['note'] == '(DC)'\n",
    "source_major_terms.drop(columns=['note'],inplace=True)\n",
    "\n",
    "source_major_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698c347-450a-4c63-b598-1784e175a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_major_terms_files = [\n",
    "'en-Major-glosses.txt',\n",
    "'es-Major-glosses.txt',\n",
    "'fr-Major-glosses.txt',\n",
    "'id-Major-glosses.txt']\n",
    "\n",
    "names = [file[:-4].replace('-','_') for file in other_major_terms_files]\n",
    "new_col_names = {file: file[:-4].replace('-','_').replace('_glosses','') for file in other_major_terms_files}\n",
    "print(new_col_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa74f98-421a-4ed5-828e-cee89f2c7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/28218698/how-to-iterate-over-columns-of-pandas-dataframe-to-run-regression\n",
    "# for idx, row in df.iterrows() iterates over rows\n",
    "# df.iteritems() does the same for columns,\n",
    "# and df.items() may be much the same.\n",
    "# Beware df[column] can be a DataFrame or a Serie if you have columns with duplicated names.\n",
    "\n",
    "other_major_terms_data = get_terms_from_files(sil_assets_path,other_major_terms_files)\n",
    "other_major_terms = pd.DataFrame.from_dict(other_major_terms_data, dtype=str)\n",
    "other_major_terms.rename(new_col_names, axis=\"columns\", inplace=True)\n",
    "other_major_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd3260-a5ea-4c53-bc1a-df348985cd37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in other_major_terms:\n",
    "    print(column)\n",
    "    other_major_terms[column] = other_major_terms[column].str.split(('\\t'), expand=False)\n",
    "\n",
    "other_major_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeace057-b8e8-4d26-b307-e21303b8574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_metadata = pd.concat([source_major_terms, other_major_terms], axis=1)\n",
    "major_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d9198-f37a-4fb1-a0eb-195c266a4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of these Original language terms are found exactly as a key in other lists?\n",
    "simple_df\n",
    "possible_match_columns = ['Original unicode', 'Hebrew Original', 'Aramaic Original', 'Greek Original', 'Greek lemma', 'Greek normalized', 'Greek gloss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60731970-eb96-442d-b800-c9d2b6b6f9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
