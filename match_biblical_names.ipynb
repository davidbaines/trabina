{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a98d7ac-bfd1-4c31-8cac-abffff84d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#from argparse import ArgumentParser\n",
    "import csv\n",
    "from collections import Counter\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from tqdm import tqdm \n",
    "import urllib.request\n",
    "\n",
    "def get_bible_text_from_url(url: str) -> list:\n",
    "    \"\"\"\n",
    "    Reads a text file from a URL, returns a list of lines.\n",
    "    Inputs:\n",
    "        filename:  URL or local filepath\n",
    "    Outputs:\n",
    "        :      Dictionary mapping semantic domains to descriptions\n",
    "    \"\"\"\n",
    "    f = urllib.request.urlopen(filename)\n",
    "    return  [line.decode('utf-8').strip('\\n') for line in f.readlines()]\n",
    "    \n",
    "    \n",
    "def get_bible_from_file(filename: str):\n",
    "    \"\"\"\n",
    "    Reads a text file, returns a DataFrame.\n",
    "    Inputs:\n",
    "        filename:  Local filepath\n",
    "    Outputs:\n",
    "        :      DataFrame with the verses and verse references.\n",
    "    \"\"\"\n",
    "    # Read in a Bible\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = [line.strip('\\n') for line in f.readlines()]\n",
    "    \n",
    "    # Convert to dictionary\n",
    "    bible_dict = {vref + 1 : verse for vref,verse in enumerate(lines)}\n",
    "\n",
    "    # Make a Dataframe from the dictionary\n",
    "    bible = pd.DataFrame.from_dict(bible_dict, orient='index', dtype=str, columns=['verse'])\n",
    "    \n",
    "    return bible\n",
    "    \n",
    "def read_terms_from_json(json_file):\n",
    "    \n",
    "    with open(json_file, 'r', encoding = 'utf-8') as json_f:\n",
    "        json_data = json.load(json_f)\n",
    "        \n",
    "    return pd.DataFrame(json_data)\n",
    "    \n",
    "    \n",
    "def get_vrefs(silnlp_vref_file):    \n",
    "    # Get the silnlp references to line numbers:\n",
    "    with open(silnlp_vref_file, 'r', encoding='utf-8') as vrefs_file:\n",
    "        vrefs_dict = {ref.strip('\\n'): i+1 for i, ref in enumerate(vrefs_file.readlines())}\n",
    "    \n",
    "    #print(f\"vrefs_dict is {vrefs_dict}\")\n",
    "    #try :\n",
    "    #    print(f\"vrefs dict contains Mark 16:99? {vrefs_dict['MRK 16:99']}\")\n",
    "    #except KeyError:\n",
    "    #    print(f\"vrefs dict doesn't contain Mark 16:99.\")\n",
    "    vrefs = pd.DataFrame([vrefs_dict]).T\n",
    "    vrefs.rename({0:'silnlp_line_number'}, axis='columns', inplace=True)\n",
    "\n",
    "    # To convert reference to line number get the 1st (index 0) element of the vrefs for that reference. E.g.:\n",
    "    #print(vrefs.loc['ENO 1:2']['silnlp_line_number'])\n",
    "    return vrefs\n",
    "\n",
    "def df_print(df):\n",
    "    print(f\"The columns are {[col for col in df]}\\n\")\n",
    "    print(df)\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49efefa-9185-4ef4-bab5-5db02c5fa975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the major terms df\n",
      "The columns are ['term', 'domain', 'en', 'es', 'fr', 'id', 'vrefs', 'silnlp_line_number']\n",
      "\n",
      "            term domain                   en        es          fr       id  \\\n",
      "0      אֲבַגְתָא     PN              Abagtha    Abagtá      Avagta   Abagta   \n",
      "6          אֲבִי     PN                  Abi       Abí         Avi      Abi   \n",
      "7          אֲבִי     PN            Abiezrite   Abiézer     Avièzer  Abiezer   \n",
      "8          אֲבִי     PN            Abiezrite   Abiézer     Avièzer  Abiezer   \n",
      "9          אֲבִי     PN            Abiezrite   Abiézer     Avièzer  Abiezer   \n",
      "...          ...    ...                  ...       ...         ...      ...   \n",
      "88265    Χριστός     PN               anoint  Atarates       Hagab            \n",
      "88266    Χριστός     PN               anoint  Atarates       Hagab            \n",
      "88267    Χριστός     PN               anoint  Atarates       Hagab            \n",
      "88268    Χριστός     PN               anoint  Atarates       Hagab            \n",
      "88429       Ὡσηέ     PN  descendant of Aaron    Ajicar  sanctuaire            \n",
      "\n",
      "           vrefs  silnlp_line_number  \n",
      "0       EST 1:10             12716.0  \n",
      "6       2KI 18:2             10030.0  \n",
      "7       JDG 6:11              6667.0  \n",
      "8       JDG 6:24              6680.0  \n",
      "9       JDG 8:32              6753.0  \n",
      "...          ...                 ...  \n",
      "88265  REV 11:15             30955.0  \n",
      "88266  REV 12:10             30969.0  \n",
      "88267   REV 20:4             31111.0  \n",
      "88268   REV 20:6             31113.0  \n",
      "88429   ROM 9:25             28248.0  \n",
      "\n",
      "[39185 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "silnlp_assets_folder = Path(\"D:/GitHub/davidbaines/trabina/silnlp/assets\")\n",
    "silnlp_vref_file = silnlp_assets_folder / \"vref.txt\"\n",
    "vrefs = get_vrefs(silnlp_vref_file)\n",
    "\n",
    "bible_folder = Path(r\"D:/Work/Corpora/eBible/corpus\")\n",
    "output_folder = Path(r\"D:/GitHub/davidbaines/trabina/data/matches\")\n",
    "data_folder = Path(r\"D:/GitHub/davidbaines/trabina/data\")\n",
    "\n",
    "pattern = 'major'\n",
    "terms_json_file = data_folder / f\"{pattern}_terms.json\"\n",
    "major = read_terms_from_json(terms_json_file)    \n",
    "isos = {'en':'en','eng':'en', 'fr':'fr', 'fra':'fr','es':'es','id':'id'}\n",
    "valid_isos = set(isos.values())\n",
    "\n",
    "# Keep only Proper Nouns\n",
    "major = major[major.domain == 'PN']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "major.drop(columns = ['sense','category','AR','DC'], inplace=True)\n",
    "\n",
    "# There are many results that don't look like names. They seem to be associated with verses in the deuterocannon.\n",
    "#Omit those for now.\n",
    "#df[df.score < 50].index\n",
    "major.drop(major[major.silnlp_line_number > 31170].index, inplace=True)\n",
    "print(\"This is the major terms df\")\n",
    "df_print(major)\n",
    "\n",
    "major_en = major.drop(major[major.en == ''].index)\n",
    "major_en = major_en.drop(columns=[iso for iso in valid_isos if iso != 'en'])\n",
    "\n",
    "major_fr = major.drop(major[major.fr == ''].index)\n",
    "major_fr = major_fr.drop(columns=[iso for iso in valid_isos if iso != 'fr'])\n",
    "\n",
    "major_es = major.drop(major[major.es == ''].index)\n",
    "major_es = major_es.drop(columns=[iso for iso in valid_isos if not iso == 'es'])\n",
    "\n",
    "major_id = major.drop(major[major['id'] == ''].index)\n",
    "major_id = major_id.drop(columns=[iso for iso in valid_isos if not iso == 'id'])\n",
    "\n",
    "major_iso = {'en':major_en, 'fr': major_fr, 'es':major_es, 'id':major_id}\n",
    "\n",
    "possible_bibles = bible_folder.glob(\"*.txt\")\n",
    "bible_versions = {bf:bf.name[:bf.name.find('-')] for bf in possible_bibles if bf.name[:bf.name.find('-')] in isos}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4873ca23-2f86-47e8-9602-a722e1e0800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:47<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to D:\\GitHub\\davidbaines\\trabina\\data\\matches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for bible_version,iso in tqdm(bible_versions.items()):\n",
    "\n",
    "    iso = isos[iso]\n",
    "\n",
    "    # Choose the dataframe that has glosses for all terms in this language.\n",
    "    major = major_iso[iso]\n",
    "\n",
    "    output_tsv = output_folder / f\"matched_{bible_version.stem}_{pattern}_names.tsv\"\n",
    "    #bible_url = r\"https://raw.githubusercontent.com/BibleNLP/ebible-corpus/main/corpus/eng-eng-web.txt\"\n",
    "\n",
    "    # Read in the Bible\n",
    "    bible = get_bible_from_file(bible_version)    \n",
    "\n",
    "    #Add in the verse line numbers and refs. \n",
    "    #We will join using the silnlp_line_numbers.\n",
    "    # The refs will be good to check with the vrefs from the major terms list.\n",
    "    bible['ref'] = vrefs.index\n",
    "    bible['silnlp_line_number'] = vrefs.silnlp_line_number.values\n",
    "\n",
    "    # Now drop empty verses. Must add the verse refs before this step!\n",
    "    bible.drop(bible[bible.verse == ''].index, inplace=True)\n",
    "    # The index of the bible and the silnlp_line_numbers should be the same throughout.\n",
    "\n",
    "    #print(\"This is the bible df\")\n",
    "    #df_print(bible)    \n",
    "\n",
    "    #print(\"This is the major terms df\")\n",
    "    #df_print(major)\n",
    "\n",
    "    # Add the verse to the terms data\n",
    "    major_bible = pd.merge(major, bible, how='inner', left_on = 'silnlp_line_number', right_on = 'silnlp_line_number')\n",
    "\n",
    "    major_bible['refs_match'] = major_bible.vrefs == major_bible.ref\n",
    "\n",
    "    #print(\"This is the major_bible df\")\n",
    "    #df_print(major_bible)\n",
    "\n",
    "    all_refs_match = len(major_bible[major_bible.refs_match == True]) == len(major_bible)\n",
    "    if not all_refs_match:\n",
    "        print(f\"These references don't match: {major_bible[major_bible.refs_match == False]}\")\n",
    "        exit()\n",
    "\n",
    "    # For each English gloss, does it appear in the verse?\n",
    "    # Add a column that indicates whether the gloss is found in the verse.\n",
    "\n",
    "    found_col = f\"{iso}_in_{bible_version}\"\n",
    "    major_bible[found_col] = major_bible.fillna('').apply(lambda row: row[iso].lower() in row.verse.lower(), axis=1)\n",
    "\n",
    "    # From https://www.statology.org/pandas-groupby-count-with-condition/\n",
    "    # groupby team and count number of 'pos' equal to 'Gu'\n",
    "    # df_count = df.groupby('team')['pos'].apply(lambda x: (x=='Gu').sum()).reset_index(name='count')\n",
    "\n",
    "    bible_wordcount_found = major_bible.groupby(iso)[found_col].apply(lambda x: (x).sum()).reset_index(name='Found')\n",
    "    bible_wordcount_not_found = major_bible.groupby(iso)[found_col].apply(lambda x: (x == False).sum()).reset_index(name='Not_found')\n",
    "    bible_wordcount = pd.merge(bible_wordcount_found,bible_wordcount_not_found)\n",
    "    bible_wordcount['Found_ratio'] = bible_wordcount.apply(lambda x: int(x[1]) / (int(x[1]) + int(x[2])), axis=1)\n",
    "    bible_wordcount.to_csv(output_tsv, sep = '\\t')\n",
    "    \n",
    "print(f\"Saved results to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ea40a-a31b-46d4-a989-1cc9cbe3cb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
